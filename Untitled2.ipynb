{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark\n",
    "import urllib2\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/conda/envs/python2/bin/python'\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is for Py2k.  For Py3k, use http.client and urllib.parse instead, and\n",
    "# use // instead of / for the division\n",
    "def unshorten_url(url):\n",
    "    if re.match(r\"https://twitter.com/i/web/status/\",url) is not None:\n",
    "        response = \"tweet response\"\n",
    "    \n",
    "    else:\n",
    "        if len(url)<40:\n",
    "                try:\n",
    "                    site= url\n",
    "                    hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 5.1; rv:10.0.1) Gecko/20100101 Firefox/10.0.1',}\n",
    "                    req = urllib2.Request(site,headers=hdr)\n",
    "                    response = urllib2.urlopen(req,timeout=8).url\n",
    "\n",
    "                except urllib2.HTTPError as x:\n",
    "                    response = 'invalid'\n",
    "                except UnicodeEncodeError:\n",
    "                    try:\n",
    "                        site = urllib2.quote(url.encode('utf8'), ':/')\n",
    "                        req = urllib2.Request(site,headers=hdr)\n",
    "                        response = urllib2.urlopen(req).url\n",
    "                    except urllib2.HTTPError as x:\n",
    "                        response = x.code\n",
    "                except Exception:\n",
    "                    response = 'invalid'\n",
    "        else:\n",
    "            response=url\n",
    "            \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def site_url(url):\n",
    "    if url =='invalid':\n",
    "        site = 'invalid' \n",
    "    elif url =='tweet response':\n",
    "        site = 'tweet response' \n",
    "    else:\n",
    "        site = re.findall(r\"http[s]?://[a-zA-Z0-9_.-]+\", url)[-1]\n",
    "\n",
    "    return site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "case = 'serbie'\n",
    "path = case+\"/\"+case+\"0001.json\"\n",
    "DFjson = spark.read.json(path)\n",
    "DFjson.createOrReplaceTempView(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DFurl = spark.sql(\"SELECT id AS tweet,user.id AS user,entities.urls.expanded_url[0]AS url \\\n",
    "FROM serbie WHERE entities.urls.expanded_url[0] is not NULL\") \n",
    "\n",
    "RDDurl  = DFurl.rdd.map(lambda x:(x[0],x[1],unshorten_url(x[2])))\n",
    "listeURL = RDDurl.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RDD_distinct_url = sc.parallelize(listeURL).map(lambda x:(x[1],x[2])).distinct()\n",
    "\n",
    "RDD_url_count =  RDD_distinct_url.map(lambda x:(x[1],1)).reduceByKey(lambda a,b:a+b)\\\n",
    ".map(lambda x: (x[1],x[0])).sortByKey(False,1).map(lambda x: (x[1],x[0]))\n",
    "\n",
    "RDD_site_count = RDD_url_count.map(lambda x:(site_url(x[0]),x[1])).reduceByKey(lambda a,b:a+b)\\\n",
    ".map(lambda x: (x[1],x[0])).sortByKey(False,1).map(lambda x: (x[1],x[0]))\n",
    "\n",
    "RDD_complete = sc.parallelize(listeURL).map(lambda x:(x[0],x[1],x[2],site_url(x[2])))\n",
    "\n",
    "RDD_user_count =  RDD_distinct_url.map(lambda x:(x[0],1)).reduceByKey(lambda a,b:a+b)\\\n",
    ".map(lambda x: (x[1],x[0])).sortByKey(False,1).map(lambda x: (x[1],x[0]))\n",
    "\n",
    "RDD_user_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DFurl2= spark.sql(\"SELECT user.id AS user \\\n",
    "FROM serbie\") \n",
    "\n",
    "RDD_user_count2 = DFurl2.rdd.map(lambda x:(x,1)).reduceByKey(lambda a,b:a+b)\\\n",
    ".map(lambda x: (x[1],x[0])).sortByKey(False,1).map(lambda x: (x[1],x[0]))\n",
    "\n",
    "RDD_user_count2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RDDaa = RDD_complete.filter(lambda x: x[2] != \"tweet response\" and x[2] != \"invalid\"  ).map(lambda x:(x[1],x[3]))\n",
    "\n",
    "PDDFnodes1 = RDDaa.map(lambda x : (x[0],1)).reduceByKey(lambda a,b:a+b)\\\n",
    ".map(lambda x : (x[0],\"user\",x[1])).toDF(['id','group','value']).toPandas()\n",
    "\n",
    "PDDFnodes2 = RDDaa.map(lambda x : (x[1],1)).reduceByKey(lambda a,b:a+b)\\\n",
    ".map(lambda x : (x[0],\"media\",x[1])).sortBy(lambda x:x[1],False).toDF(['id','group','value']).toPandas()\n",
    "\n",
    "PDDFlinks = RDDaa.map(lambda x:(x[0],x[1],1))\\\n",
    ".sortBy(lambda x:x[2],False).toDF(['source','target','value']).toPandas()\n",
    "\n",
    "PDDFnodes = PDDFnodes1.append(PDDFnodes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1249436738, u'https://francais.rt.com'),\n",
       " (766326009868189696, 'https://francais.rt.com'),\n",
       " (3148293489, u'https://francais.rt.com'),\n",
       " (2545341344, 'http://www.ulyces.co'),\n",
       " (864276409, u'https://francais.rt.com')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDDaa.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"nodes.json\", \"w\") as text_file:\n",
    "    text_file.write(PDDFnodes.to_json(orient='records'))\n",
    "    \n",
    "with open(\"links.json\", \"w\") as text_file:\n",
    "    text_file.write(PDDFlinks.to_json(orient='records'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
